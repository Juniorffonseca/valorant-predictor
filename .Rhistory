plot(n, color = 'blue')
# Extrair os dados de nós da rede neural
nos <- rede_neural$net.result
rede_neural <- n
# Extrair os dados de nós da rede neural
nos <- rede_neural$net.result
# Personalizar as cores dos nós
cores <- c("red", "blue", "green")
# Plotar a rede neural com rótulos nos nós
plot(nos, col = cores, pch = 19, xlab = "Entrada", ylab = "Saída")
# Extrair os dados de nós da rede neural
nos <- rede_neural$net.result
# Personalizar as cores dos nós
cores <- c("red", "blue", "green")
# Plotar a rede neural com rótulos nos nós
plot(nos, col = cores, pch = 19, xlab = "Entrada", ylab = "Saída")
# Extrair os dados de nós da rede neural
nos <- rede_neural$net.result
# Personalizar as cores dos nós
cores <- c("red", "blue", "green")
# Plotar a rede neural com rótulos nos nós
plot(nos, col = cores, pch = 19)
# Extrair os dados de nós da rede neural
nos <- rede_neural$net.result
# Personalizar as cores dos nós
cores <- c("red", "blue", "green")
# Plotar a rede neural com rótulos nos nós
plot(nos)
# Carregando pacotes --------------------------------------------------------------------------------------
library(rvest)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(reshape2)
library(tidyverse)
library(neuralnet)
library(readr)
library(purrr)
library(valorant)
library(lubridate)
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
nome_arquivo_urls <- paste(Sys.Date(), '_urls.csv', sep = '')
nome_arquivo_previsoes <- paste(Sys.Date(), '_previsoes.csv', sep = '')
nome_arquivo_acuracia <- paste(Sys.Date(), '_acuracia.csv', sep = '')
b <- read.csv2(paste('csv/catalogacao_diaria/', nome_arquivo_urls, sep = '')) %>% select(-X) %>% unlist()
previsoes <- read.csv2(paste('csv/previsao_diaria/', nome_arquivo_previsoes, sep = '')) %>% select(-X)
ganhador <- '' %>% .[0]
for (i in b){
ganhador[length(ganhador)+1] <- get_Ganhadores(i)
}
df <- cbind(b, previsoes)
df$ganhador <- ganhador
library(valorant)
# Carregando pacotes --------------------------------------------------------------------------------------
library(rvest)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(reshape2)
library(tidyverse)
library(neuralnet)
library(readr)
library(purrr)
library(valorant)
library(lubridate)
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
nome_arquivo_urls <- paste(Sys.Date(), '_urls.csv', sep = '')
nome_arquivo_previsoes <- paste(Sys.Date(), '_previsoes.csv', sep = '')
nome_arquivo_acuracia <- paste(Sys.Date(), '_acuracia.csv', sep = '')
b <- read.csv2(paste('csv/catalogacao_diaria/', nome_arquivo_urls, sep = '')) %>% select(-X) %>% unlist()
previsoes <- read.csv2(paste('csv/previsao_diaria/', nome_arquivo_previsoes, sep = '')) %>% select(-X)
for (i in b){
ganhador[length(ganhador)+1] <- get_Ganhadores(i)
}
ganhador <- '' %>% .[0]
for (i in b){
ganhador[length(ganhador)+1] <- get_Ganhadores(i)
}
ganhador
b <- b[1:25]
previsoes <- previsoes[1:25]
previsoes <- previsoes[1:25,]
View(previsoes)
df <- cbind(b, previsoes)
View(df)
df$ganhador <- ganhador
df <- df[-24,]
df <- df[-22,]
df$V1_n <- as.numeric(ifelse(is.na(str_extract(df$V1, "\\d{1,2}[.,]\\d{1,2}")),
str_extract(df$V1, "\\d{1,2}"),
str_extract(df$V1, "\\d{1,2}[.,]\\d{1,2}")))
df$V2_n <- as.numeric(ifelse(is.na(str_extract(df$V2, "\\d{1,2}[.,]\\d{1,2}")),
str_extract(df$V2, "\\d{1,2}"),
str_extract(df$V2, "\\d{1,2}[.,]\\d{1,2}")))
df$prev <- ifelse(as.numeric(df$V1_n)>as.numeric(df$V2_n), 1, 0)
acertos <- sum(df$ganhador == df$prev)
erros <- sum(df$ganhador != df$prev)
acuracia <- acertos/nrow(df)
source("~/TCC_Pós/Scripts/analise_descritiva_amostras.R")
source("~/TCC_Pós/Scripts/analise_descritiva_amostras.R")
source("~/TCC_Pós/Scripts/analise_descritiva_amostras.R")
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), ('2023-04-09'), by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), ('2023-04-09'), by = 'day')
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), as.Date('2023-04-09'), by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
jogos_lista <- list()
urls_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
# Instalando (se necessário) e carregando pacotes ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), as.Date('2023-04-09'), by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
urls_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
# Instalando (se necessário) e carregando pacotes ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), as.Date('2023-04-09'), by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
urls <- bind_rows(urls_lista) %>% select(-X)
View(urls_lista)
urls <- bind_rows(urls_lista) %>% select(-'X')
urls <- bind_rows(urls_lista) %>% select(-1)
urls <- bind_rows(urls_lista)
View(urls_lista)
urls <- bind_rows(urls_lista[2])
View(urls)
urls <- bind_rows(urls_lista[,2])
urls <- bind_rows(urls_lista[[2]])
urls <- bind_rows(urls_lista[[,2]])
urls <- bind_rows(urls_lista[][2])
urls <- bind_rows(lapply(urls_lista, select, 2))
urls <- bind_rows(as.character(urls_lista))
df_list <- lapply(df_list, function(df) {
df$x <- as.character(df$x)
return(df)
})
df_list <- lapply(urls_lista, function(df) {
df$x <- as.character(df$x)
return(df)
})
View(df_list)
# Instalando (se necessário) e carregando pacotes ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), as.Date('2023-04-09'), by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
urls_lista <- lapply(urls_lista, function(df) {
df$x <- as.character(df$x)
return(df)
})
# Instalando (se necessário) e carregando pacotes ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), as.Date('2023-04-09'), by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
urls_lista <- lapply(urls_lista, function(df) {
df$x <- as.character(df$x)
return(df)
})
urls <- bind_rows(urls_lista)
urls
View(urls)
View(urls)
View(urls)
View(urls)
urls <- bind_rows(urls_lista) %>% select(-X)
View(urls)
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
write.csv2(urls, 'csv/urls_utilizados.csv')
nomes_times <- list()
for (url in urls){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
}
for (url in urls){
nomes_times[length(nomes_times)+1] <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
}
for (url in urls[,]){
nomes_times[length(nomes_times)+1] <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
}
nomes_times
View(nomes_times)
warnings()
read_html(urls[1]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times[length(nomes_times)+1] <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
}
View(urls)
nomes_times
read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
z <- read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_times <- matrix(nrow = 0, ncol = 2)
nomes_times <- read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_times <- matrix(nrow = 0, ncol = 2)
nomes_times[length(nomes_times)+1] <- read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_times[length(nomes_times)+2] <- read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_times <- matrix(nrow = 0, ncol = 2)
nomes_times[length(nomes_times)+2] <- read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_times[length(nomes_times)+1,] <- read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_times <- matrix(nrow = 0, ncol = 2)
nomes_times <- read_html(urls[1,]) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind()
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind()
}
View(urls)
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind(nomes_times, .)
}
nomes_times
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind(nomes_times)
}
nomes_times
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind(nomes_times)
}
nomes_times
View(urls)
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind(nomes_times)
}
View(nomes_times)
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind(nomes_times)
}
nomes_times
View(urls)
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind(nomes_times)
}
nomes_times
nomes_times[1,]
nomes_times[,1]
x <- as.data.frame(nomes_times)
View(x)
nomes_times <- as.data.frame(nomes_times)
rm(x)
nomes_times[674:1]
nomes_times[674:1,]
nomes_times <- as.data.frame(nomes_times) %>% [length():1]
nomes_times <- as.data.frame(nomes_times) %>% .[length():1]
nomes_times <- as.data.frame(nomes_times) %>% .[length(.):1]
View(nomes_times)
nomes_times <- as.data.frame(nomes_times) %>% nomes_times[length(.):1]
nomes_times <- as.data.frame(nomes_times) %>% .[length(nomes_times):1]
View(nomes_times)
nomes_times <- as.data.frame(nomes_times) %>% .[length(.):1,]
View(nomes_times)
x
nomes_times <- matrix(nrow = 0, ncol = 2)
for (url in urls[,]){
nomes_times <- read_html(url) %>% html_nodes("div.wf-title-med") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% rbind(nomes_times)
}
nomes_times <- as.data.frame(nomes_times) %>% slice(rev(row_number))
backup <- nomes_times
nomes_times <- as.data.frame(nomes_times) %>%
rev() %>%
`rownames<-`(NULL)
View(nomes_times)
nomes_times <- as.data.frame(nomes_times) %>%
rev() %>%
`rownames<-`(NULL) %>% slice(rev(row_number()))
View(nomes_times)
nomes_times <- backup
nomes_times <- as.data.frame(nomes_times) %>%
rev() %>%
`rownames<-`(NULL) %>% slice(rev(row_number()))
View(nomes_times)
nomes_times <- backup
nomes_times <- as.data.frame(nomes_times) %>%
`rownames<-`(NULL) %>% slice(rev(row_number()))
View(nomes_times)
write.csv2(nomes_times, 'csv/times_catalogados.csv')
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text()
nomes_jogadores
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"")
nomes_jogadores
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% select(1:10)
nomes_jogadores
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% select(., 1:10)
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% .(1:10)
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% select(1:10,)
nomes_jogadores(1:10)
nomes_jogadores[1:10]
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% [1:10]
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t",
"") %>% .[1:10]
nomes_jogadores
nomes_jogadores <- matrix(nrow = 0, ncol = 10)
nomes_jogadores <- matrix(nrow = 0, ncol = 10)
for(url in urls[,]){
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t", "") %>%
.[1:10] %>% rbind(nomes_jogadores)
}
nomes_jogadores
View(nomes_jogadores)
nomes_jogadores <- matrix(nrow = 0, ncol = 10)
for(url in urls[,]){
nomes_jogadores <- read_html(url) %>% html_nodes("td.mod-player a") %>%
html_text() %>% str_replace_all("\n", "") %>% str_replace_all("\t", "") %>%
.[1:10] %>% rbind(nomes_jogadores)
}
backup <- nomes_jogadores
View(nomes_jogadores)
nomes_jogadores <- as.data.frame(nomes_jogadores) %>%
`rownames<-`(NULL) %>% slice(rev(row_number()))
View(nomes_jogadores)
write.csv2(nomes_jogadores, 'csv/jogadores_catalogados.csv')
unique(nomes_jogadores)
count(unique(nomes_jogadores))
count(max(nomes_jogadores))
count(unique(nomes_times))
count(max(nomes_jogadores[,]))
count(max(nomes_jogadores))
count(unique(nomes_jogadores[]))
count(unique(nomes_jogadores[,]))
View(nomes_jogadores)
sapply(nomes_jogadores, function(x) length(unique(x)))
# Número de times únicos:
count(unique(nomes_times)) #628
sapply(nomes_jogadores, function(x) length(unique(x)))
sum(sapply(nomes_jogadores, function(x) length(unique(x))))
# Número de jogadores únicos:
sum(sapply(nomes_jogadores, function(x) length(unique(x)))) #
histogram(nomes_jogadores)
histogram(nomes_times)
histogram(nomes_times$V1)
histogram(count(nomes_times))
histogram(count(nomes_times$V1))
histogram(count(unique(nomes_times$V1)))
