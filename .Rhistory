for (i in seq_along(folds)) {
# Divide os dados em treinamento e teste
training_data <- jogos[folds[[i]], ]
test_data <- jogos[-folds[[i]], ]
# Treina a rede neural
modelo_neural <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = t,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 100000000)
# Faz as predições no conjunto de teste
predicoes <- predict(modelo_neural, test_data[, -ncol(test_data)])
classes_preditas <- ifelse(predicoes > 0.5, 1, 0)
# Avalia o modelo
matriz_confusao <- table(classes_preditas, test_data$ganhador, dnn = c("Predições", "Classes Reais"))
acuracia <- sum(diag(matriz_confusao))/sum(matriz_confusao)
resultados[[i]] <- acuracia
}
# Calcula a acurácia média
acuracia_media <- mean(unlist(resultados))
# Verifica se a acurácia mínima foi atingida
if (acuracia_media >= acuracia_minima) {
break
}
}
seed <- 1
seed <- 1
# Define o número de folds
num_folds <- 5
# Define a acurácia mínima desejada
acuracia_minima <- 0.65
seed <- 1
# Loop até atingir a acurácia mínima
while (TRUE) {
# Iteração das seeds
set.seed(seed)
# Cria os folds
folds <- createFolds(jogos$ganhador, k = num_folds)
# Loop pelos folds
resultados <- list()
for (i in seq_along(folds)) {
# Divide os dados em treinamento e teste
training_data <- jogos[folds[[i]], ]
test_data <- jogos[-folds[[i]], ]
# Treina a rede neural
modelo_neural <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = t,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 100000000)
# Faz as predições no conjunto de teste
predicoes <- predict(modelo_neural, test_data[, -ncol(test_data)])
classes_preditas <- ifelse(predicoes > 0.5, 1, 0)
# Avalia o modelo
matriz_confusao <- table(classes_preditas, test_data$ganhador, dnn = c("Predições", "Classes Reais"))
acuracia <- sum(diag(matriz_confusao))/sum(matriz_confusao)
resultados[[i]] <- acuracia
seed <- seed + 1
}
# Calcula a acurácia média
acuracia_media <- mean(unlist(resultados))
# Verifica se a acurácia mínima foi atingida
if (acuracia_media >= acuracia_minima) {
break
}
}
# Loop até atingir a acurácia mínima
while (TRUE) {
# Iteração das seeds
set.seed(seed)
# Cria os folds
folds <- createFolds(jogos$ganhador, k = num_folds)
# Loop pelos folds
resultados <- list()
for (i in seq_along(folds)) {
# Divide os dados em treinamento e teste
training_data <- jogos[folds[[i]], ]
test_data <- jogos[-folds[[i]], ]
# Treina a rede neural
modelo_neural <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = t,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 100000000)
# Faz as predições no conjunto de teste
predicoes <- predict(modelo_neural, test_data[, -ncol(test_data)])
classes_preditas <- ifelse(predicoes > 0.5, 1, 0)
# Avalia o modelo
matriz_confusao <- table(classes_preditas, test_data$ganhador, dnn = c("Predições", "Classes Reais"))
acuracia <- sum(diag(matriz_confusao))/sum(matriz_confusao)
resultados[[i]] <- acuracia
seed <- seed + 1
}
# Calcula a acurácia média
acuracia_media <- mean(unlist(resultados))
cat('Acurácia encontrada nesse loop:', acuracia_media, '\n')
# Verifica se a acurácia mínima foi atingida
if (acuracia_media >= acuracia_minima) {
break
}
}
# Definir as grades de valores para cada hiperparâmetro
grade_neurons <- c(5, 10, 15, 20)
grade_learning_rate <- c(0.01, 0.05, 0.1)
grade_num_layers <- c(1, 2, 3)
# Criar a função para treinar e avaliar o modelo
treina_avalia_modelo <- function(neurons, learning_rate, num_layers) {
# Código para treinar e avaliar o modelo, usando os hiperparâmetros especificados
# ...
# Retorna a acurácia média do modelo obtida com os hiperparâmetros especificados
return(mean(acuracias))
}
# Criar todas as combinações possíveis de hiperparâmetros
combinacoes <- expand.grid(
neurons = grade_neurons,
learning_rate = grade_learning_rate,
num_layers = grade_num_layers
)
# Iterar por cada combinação de hiperparâmetros e treinar/avaliar o modelo
resultados <- c()
for (i in 1:nrow(combinacoes)) {
hiperparametros <- combinacoes[i,]
acuracia_media <- treina_avalia_modelo(
neurons = hiperparametros$neurons,
learning_rate = hiperparametros$learning_rate,
num_layers = hiperparametros$num_layers
)
resultados <- c(resultados, acuracia_media)
}
# Definir as grades de valores para cada hiperparâmetro
grade_neurons <- c(5, 10, 15, 20)
grade_learning_rate <- c(0.01, 0.05, 0.1)
grade_num_layers <- c(1, 2, 3)
treina_avalia_modelo <- function(neurons, learning_rate, num_layers) {
# Define a fórmula para a rede neural
formula <- as.formula(paste0('classe ~ ', paste0(names(dados_treino[, -ncol(dados_treino)]), collapse = ' + ')))
# Define o conjunto de dados de treinamento e teste para o k-fold cross-validation
k <- 5
conjunto_particionado <- createDataPartition(dados_treino$classe, p = 0.8, list = F)
particoes <- cut(conjunto_particionado, breaks = k, labels = FALSE)
acuracias <- c()
for (i in 1:k) {
# Define o conjunto de treinamento e teste para a iteração atual do k-fold cross-validation
conjunto_teste <- subset(dados_treino, particoes == i)
conjunto_treinamento <- subset(dados_treino, particoes != i)
# Treina a rede neural com os hiperparâmetros especificados
modelo_neural <- neuralnet(
formula,
data = conjunto_treinamento,
hidden = rep(neurons, num_layers),
err.fct = 'sse',
linear.output = F,
threshold = 0.01,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
learningrate = learning_rate,
stepmax = 100000000
)
# Faz as predições no conjunto de teste
predicoes <- predict(modelo_neural, conjunto_teste[, -ncol(conjunto_teste)])
classes_preditas <- ifelse(predicoes > 0.5, 1, 0)
# Calcula a acurácia no conjunto de teste
acuracia <- sum(classes_preditas == conjunto_teste$classe) / nrow(conjunto_teste)
acuracias <- c(acuracias, acuracia)
}
# Retorna a acurácia média do modelo obtida com os hiperparâmetros especificados
return(mean(acuracias))
}
# Instalando pacotes (se necessário) e carregando ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(time1FKPR, time1FDPR, time1KPR, time1APR, time1KD, time1R, time1ADR,
time2FKPR, time2FDPR, time2KPR, time2APR, time2KD, time2R, time2ADR,
ganhador)
jogos$ganhador <- as.factor(jogos$ganhador)
#write.csv2(jogos, 'csv/partidas_teste.csv')
#jogos <- read.csv2('csv/partidas_teste.csv')
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
data_split <- initial_split(jogos, prop = 0.7, strata = 'ganhador')
training_data <- training(data_split)
test_data <- testing(data_split)
hidden_n <- c(10)
#hidden_n <- c(30)
# formula <- 'ganhador == 1 ~ time1FKPR + time1FDPR + time1KPR + time1APR + time1KD + time1R + time1ADR +
# time2FKPR + time2FDPR + time2KPR + time2APR + time2KD + time2R + time2ADR'
formula <- 'ganhador == 1 ~ .'
# Normalizando os dados ------------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = t,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
while ( i < 0.79) {
achar_Seed(s, hidden_n, t = 0.5, mostrar_i = F)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(time1FKPR, time1FDPR, time1KPR, time1APR, time1KD, time1R, time1ADR,
time2FKPR, time2FDPR, time2KPR, time2APR, time2KD, time2R, time2ADR,
ganhador)
jogos$ganhador <- as.factor(jogos$ganhador)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
data_split <- initial_split(jogos, prop = 0.7, strata = 'ganhador')
training_data <- training(data_split)
test_data <- testing(data_split)
hidden_n <- c(10)
# formula <- 'ganhador == 1 ~ time1FKPR + time1FDPR + time1KPR + time1APR + time1KD + time1R + time1ADR +
# time2FKPR + time2FDPR + time2KPR + time2APR + time2KD + time2R + time2ADR'
formula <- 'ganhador == 1 ~ .'
# Normalizando os dados ------------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = t,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
library(glmnet)
library(glmnet)
# Instalando pacotes (se necessário) e carregando ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
vars <- setdiff(names(jogos), "ganhador")
#Normalize as variáveis:
x <- scale(jogos[, vars])
y <- jogos$ganhador
#Ajuste o modelo usando a função glmnet():
fit <- glmnet(x, y, family = "binomial", alpha = 1)
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1)
lambda.min <- cvfit$lambda.min
#Selecione as variáveis que têm coeficientes não nulos usando o valor do parâmetro lambda selecionado:
coeficients <- coef(fit, s = lambda.min)
selected_vars <- vars[coeficients[-1] != 0]
selected_vars
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-x)
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
variaveis_preditoras <- subset(jogos, select = -c(ganhador))
variavel_resposta <- jogos$ganhador
# Normalizar as variáveis preditoras
variaveis_preditoras_norm <- scale(variaveis_preditoras)
jogos_normalizados <- cbind(variaveis_preditoras, variavel_resposta)
# Ajustar um modelo de regressão logística com as variáveis preditoras normalizadas
modelo <- glm(variavel_resposta ~ ., data = jogos_normalizados, family = 'binomial')
# Examinar a importância de cada variável no modelo
importancia <- abs(coef(modelo))
importancia_rel <- importancia/sum(importancia)
importancia_rel
# Criar um gráfico de barras para visualizar as importâncias relativas
barplot(importancia_rel, horiz = TRUE, las = 1, main = 'Importância Relativa das Variáveis')
vars <- setdiff(names(jogos), "ganhador")
#Normalize as variáveis:
x <- scale(jogos[, vars])
y <- jogos$ganhador
#Ajuste o modelo usando a função glmnet():
fit <- glmnet(x, y, family = "binomial", alpha = 1)
#Aqui, x é uma matriz das variáveis preditoras normalizadas e y é a variável de resposta. O argumento family = "binomial" indica que estamos ajustando um modelo de regressão logística. O argumento alpha = 1 indica que estamos usando o LASSO.
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1)
lambda.min <- cvfit$lambda.min
#Aqui, cv.glmnet() realiza validação cruzada para selecionar o valor ótimo do parâmetro lambda. O argumento family = "binomial" indica que estamos ajustando um modelo de regressão logística. O argumento alpha = 1 indica que estamos usando o LASSO.
#Selecione as variáveis que têm coeficientes não nulos usando o valor do parâmetro lambda selecionado:
coeficients <- coef(fit, s = lambda.min)
selected_vars <- vars[coeficients[-1] != 0]
selected_vars
selected_vars
# Selecione as variáveis que serão usadas para ajustar o modelo
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
# Crie novas variáveis que calculam a diferença entre todas as estatísticas dos dois times
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
vars <- setdiff(names(jogos), "ganhador")
#Normalize as variáveis:
x <- scale(jogos[, vars])
y <- jogos$ganhador
# Remova as colunas das variáveis originais
jogos_diff <- jogos %>% select(ends_with("_diff"), ganhador)
vars <- setdiff(names(jogos_diff), "ganhador")
vars <- setdiff(names(jogos_diff), "ganhador")
#Normalize as variáveis:
x <- scale(jogos_diff[, vars])
y <- jogos_diff$ganhador
#Ajuste o modelo usando a função glmnet():
fit <- glmnet(x, y, family = "binomial", alpha = 1)
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1)
lambda.min <- cvfit$lambda.min
#Selecione as variáveis que têm coeficientes não nulos usando o valor do parâmetro lambda selecionado:
coeficients <- coef(fit, s = lambda.min)
selected_vars <- vars[coeficients[-1] != 0]
selected_vars
jogos_diff <- select(selected_vars)
jogos_diff <- select(jogos_diff, selected_vars)
# Instalando pacotes (se necessário) e carregando ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
# Selecione as variáveis que serão usadas para ajustar o modelo
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
# Crie novas variáveis que calculam a diferença entre todas as estatísticas dos dois times
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
# Remova as colunas das variáveis originais
jogos_diff <- jogos %>% select(ends_with("_diff"), ganhador)
vars <- setdiff(names(jogos_diff), "ganhador")
#Normalize as variáveis:
x <- scale(jogos_diff[, vars])
y <- jogos_diff$ganhador
#Ajuste o modelo usando a função glmnet():
fit <- glmnet(x, y, family = "binomial", alpha = 1)
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1)
lambda.min <- cvfit$lambda.min
#Selecione as variáveis que têm coeficientes não nulos usando o valor do parâmetro lambda selecionado:
coeficients <- coef(fit, s = lambda.min)
selected_vars <- vars[coeficients[-1] != 0]
selected_vars
jogos_diff <- select(jogos_diff, selected_vars, ganhador)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
# Selecione as variáveis que serão usadas para ajustar o modelo
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
# Crie novas variáveis que calculam a diferença entre todas as estatísticas dos dois times
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
# Remova as colunas das variáveis originais
jogos_diff <- jogos %>% select(ends_with("_diff"), ganhador)
vars <- setdiff(names(jogos_diff), "ganhador")
#Normalize as variáveis:
x <- scale(jogos_diff[, vars])
y <- jogos_diff$ganhador
x
#Ajuste o modelo usando a função glmnet():
fit <- glmnet(x, y, family = "binomial", alpha = 1)
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1)
lambda.min <- cvfit$lambda.min
#Selecione as variáveis que têm coeficientes não nulos usando o valor do parâmetro lambda selecionado:
coeficients <- coef(fit, s = lambda.min)
selected_vars <- vars[coeficients[-1] != 0]
selected_vars
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1, nfolds = 5)
set.seed(13)
#Ajuste o modelo usando a função glmnet():
fit <- glmnet(x, y, family = "binomial", alpha = 1)
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1, nfolds = 5)
lambda.min <- cvfit$lambda.min
accuracy <- cv_fit$cvm[cv_fit$lambda == cv_fit$lambda.min]
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cvfit <- cv.glmnet(x, y, family = "binomial", alpha = 1, nfolds = 5)
accuracy <- cv_fit$cvm[cv_fit$lambda == cv_fit$lambda.min]
#Selecione o valor do parâmetro lambda usando a função cv.glmnet():
cv_fit <- cv.glmnet(x, y, family = "binomial", alpha = 1, nfolds = 5)
accuracy <- cv_fit$cvm[cv_fit$lambda == cv_fit$lambda.min]
plot(cv_fit)
