formula <- as.formula("ganhador ~ .")
formula
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "backprop",
learningrate = 0.01,
hidden = c(10),
stepmax = 1e6,
err.fct = "ce"))
warnings()
metodo <- "neuralnet"
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "backprop",
learningrate = 0.01,
hidden = c(10),
stepmax = 1e6,
err.fct = "ce"))
View(modelo)
previsoes <- predict(modelo, newdata = dados_teste)
previsoes <- predict(modelo, newdata = test_data)
caret::confusionMatrix(previsoes, dados_teste$ganhador)
caret::confusionMatrix(previsoes, test_data$ganhador)
?neuralnet
argumentos <- list(hidden = c(30), linear.output = FALSE)
metodo <- "neuralnet"
formula <- as.formula("ganhador ~ .")
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "backprop",
learningrate = 0.01,
hidden = c(30),
stepmax = 1e6,
err.fct = "ce"))
previsoes <- predict(modelo, newdata = test_data)
caret::confusionMatrix(previsoes, test_data$ganhador)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "backprop",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "ce"))
previsoes <- predict(modelo, newdata = test_data)
caret::confusionMatrix(previsoes, test_data$ganhador)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "ce"))
previsoes <- predict(modelo, newdata = test_data)
caret::confusionMatrix(previsoes, test_data$ganhador)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"))
previsoes <- predict(modelo, newdata = test_data)
caret::confusionMatrix(previsoes, test_data$ganhador)
# Definir a grade de hiperparâmetros a serem testados
grid <- expand.grid(
hidden = list(c(30, 50, 100)),
learningrate = c(0.1, 0.5, 1),
decay = c(0, 0.001, 0.01)
)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
# Definir a grade de hiperparâmetros a serem testados
grid <- expand.grid(
hidden = list(c(30, 50, 100)),
mtry = c(2, 4, 6),
learningrate = c(0.1, 0.5, 1),
decay = c(0, 0.001, 0.01)
)
argumentos <- list(hidden = c(30), linear.output = FALSE)
metodo <- "neuralnet"
formula <- as.formula("ganhador ~ .")
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
# Definir a grade de hiperparâmetros a serem testados
grid <- expand.grid(
hidden = list(c(30, 50, 100)),
mtry = c(2, 4, 6),
learningrate = c(0.1, 0.5, 1),
decay = c(0, 0.001, 0.01)
)
argumentos <- list(hidden = c(30), linear.output = FALSE)
metodo <- "neuralnet"
formula <- as.formula("ganhador ~ .")
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
# Definir a grade de hiperparâmetros a serem testados
grid <- expand.grid(
hidden = list(c(30, 50, 100)),
mtry = c(2, 4, 6),
learningrate = c(0.1, 0.5, 1),
decay = c(0, 0.001, 0.01),
nodesize = c(5, 10, 15)
)
argumentos <- list(hidden = c(30), linear.output = FALSE)
metodo <- "neuralnet"
formula <- as.formula("ganhador ~ .")
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
# Definir a grade de hiperparâmetros a serem testados
grid <- expand.grid(
mtry = c(2, 4, 6),
ntree = c(100, 200, 300),
nodesize = c(5, 10, 15)
)
argumentos <- list(hidden = c(30), linear.output = FALSE)
metodo <- "neuralnet"
formula <- as.formula("ganhador ~ .")
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = tuneControl,
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = tuneControl,
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
tuneControl <- trainControl(method = "cv", number = 5)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = tuneControl,
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"),
tuneGrid = grid)
modelo <- train(formula,
data = training_data,
method = "rf",
trControl = trainControl(method = "boot"),
method.args = list(method = metodo,
linear.output = FALSE,
algorithm = "rprop-",
learningrate = 0.5,
hidden = c(30),
stepmax = 1e6,
err.fct = "sse"))
previsoes <- predict(modelo, newdata = test_data)
caret::confusionMatrix(previsoes, test_data$ganhador)
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025))
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnfit$results
modelo.final <- nnfit$finalModel
pred <- predict(modelo.final, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
modelo.final
?expand.grid
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025), .hidden = c(1:15,1:15))
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025), .hidden = c(1:15,1:15),
.decay = c(0, .005))
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnGrid <- expand.grid(
.size = c(7, 10, 15),
.decay = c(0, 0.001, 0.01, 0.1),
.maxit = c(500, 1000, 2000),
.entropy = c(TRUE, FALSE),
.maxNWts = c(1000, 2000, 5000)
)
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = c(7, 10, 15),
decay = c(0, 0.001, 0.01, 0.1),
maxit = c(500, 1000, 2000),
linout = c(TRUE, FALSE),
entropy = c(TRUE, FALSE),
maxNWts = c(1000, 2000, 5000)
)
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnfit$results
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = c(7, 10, 15),
decay = c(0, 0.001, 0.01, 0.1),
maxit = c(500, 1000, 2000),
linout = c(TRUE, FALSE),
entropy = c(TRUE, FALSE),
maxNWts = c(1000, 2000, 5000)
)
# Definir a fórmula para o modelo
formula <- as.formula("ganhador ~ .")
# Definir o método de treinamento da Rede Neural
metodo <- "nnet"
# Definir a função de controle de treinamento
tuneControl <- trainControl(method = "cv", number = 5)
# Realizar o tuning dos hiperparâmetros
modelo_tune <- train(
formula,
data = training_data,
method = metodo,
trControl = tuneControl,
tuneGrid = nnGrid,
preProcess = c("center", "scale"),
trace = FALSE
)
update.packages(caret)
update.packages('caret')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = 7,
decay = c(0, 0.001, 0.01, 0.1),
maxit = c(500, 1000, 2000),
linout = c(TRUE, FALSE),
entropy = c(TRUE, FALSE),
maxNWts = c(1000, 2000, 5000)
)
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = 7,
decay = 0.01,
maxit = c(500, 1000, 2000),
linout = c(TRUE, FALSE),
entropy = c(TRUE, FALSE),
maxNWts = c(1000, 2000, 5000)
)
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
View(nnGrid)
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = 7,
decay = 0.01,
)
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = 7,
decay = 0.01,
)
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = 7,
decay = 0.01
)
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnfit$results
# Definir a grade de hiperparâmetros a serem testados
nnGrid <- expand.grid(
size = 7,
hidden = c(15,30,45)
)
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnGrid <- expand.grid(
size = c(7, 10),
decay = c(0.001, 0.01),
maxit = c(500, 1000, 2000),
linout = c(TRUE, FALSE),
entropy = c(TRUE, FALSE),
maxNWts = c(1000, 2000, 5000),
threshold = c(0.1, 0.5, 0.9),
skip = c(0, 1, 2)
)
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
mlpGrid <- expand.grid(
size = c(7, 10),
decay = c(0.001, 0.01),
maxit = c(500, 1000, 2000),
entropy = c(TRUE, FALSE),
maxNWts = c(1000, 2000, 5000),
learnFuncParams = list(0.1, 0.01),
hidden = c(1, 2, 3)
)
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='mlp',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnGrid <- expand.grid(
size = c(7, 10, 15),
decay = c(0, 0.001, 0.01, 0.1),
maxit = c(500, 1000, 2000),
linout = c(TRUE, FALSE),
entropy = c(TRUE, FALSE),
maxNWts = c(1000, 2000, 5000)
)
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='mlp',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnGrid <- expand.grid(
size = c(7, 10, 15))
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(formula,
data=training_data,
method='mlp',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnfit$results
