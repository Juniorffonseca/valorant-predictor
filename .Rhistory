layer_dense(units = 15, input_shape = 15) %>%
layer_dense(units = 1)
# Copie os pesos da rede neural para o modelo Keras
weights <- getWeights(n)
weights_keras <- list()
for (i in 1:length(weights)) {
weights_keras[[i]] <- array(weights[[i]], dim = dim(weights[[i]])[2:1])
}
# Copie os pesos da rede neural para o modelo Keras
weights <- n$weights
weights_keras <- list()
for (i in 1:length(weights)) {
weights_keras[[i]] <- array(weights[[i]], dim = dim(weights[[i]])[2:1])
}
for (i in 1:length(weights)) {
n <- nn$act.fct[[i + 1]]$n
m <- nn$act.fct[[i]]$n + 1
weights_keras[[i]] <- array(weights[[i]]$W, dim = c(n, m))
}
nn <- n
# Copie os pesos da rede neural para o modelo Keras
weights <- nn$weights
weights_keras <- list()
for (i in 1:length(weights)) {
n <- nn$act.fct[[i + 1]]$n
m <- nn$act.fct[[i]]$n + 1
weights_keras[[i]] <- array(weights[[i]]$W, dim = c(n, m))
}
for (i in 1:length(weights)) {
n <- nn$net.layers[[i + 1]]
m <- nn$net.layers[[i]] + 1
weights_keras[[i]] <- array(weights[[i]]$W, dim = c(n, m))
}
for (i in 1:length(weights)) {
n <- nn$net.layers[[i + 1]]
m <- nn$net.layers[[i]] + 1
if (is.null(weights[[i]]$W) || any(is.na(weights[[i]]$W))) {
weights_keras[[i]] <- array(0, dim = c(n, m))
} else {
weights_keras[[i]] <- array(weights[[i]]$W, dim = c(n, m))
}
}
m <- nn$net.layers[[i]] + 1
for (i in 1:length(weights)) {
n <- nn$net.layers[[i + 1]]
m <- nn$net.layers[[i]] + 1
if (length(weights[[i]]) == 0) {
weights_keras[[i]] <- array(0, dim = c(n, m))
} else {
weights_keras[[i]] <- array(weights[[i]]$W, dim = c(n, m))
}
}
for (i in 1:length(weights)) {
n <- nn$net.layers[[i + 1]]
m <- nn$net.layers[[i]] + 1
if (length(weights[[i]]$W) == 0 || any(is.na(weights[[i]]$W))) {
weights_keras[[i]] <- array(0, dim = c(n, m))
} else {
weights_keras[[i]] <- array(weights[[i]]$W, dim = c(n, m))
}
}
n <- nn$net.layers[[i + 1]]
for (i in 1:length(weights)) {
n <- nn$net.layers[[i + 1]]
m <- nn$net.layers[[i]] + 1
if (length(weights[[i]]$W) == 0 || any(is.na(weights[[i]]$W))) {
weights_keras[[i]] <- array(0, dim = c(n, m))
} else if (length(dim(weights[[i]]$W)) == 0) {
weights_keras[[i]] <- array(0, dim = c(n, m))
} else {
weights_keras[[i]] <- array(weights[[i]]$W, dim = c(n, m))
}
}
# Compile o modelo
model_keras %>% compile(
loss = "mse",
optimizer = optimizer_adam(lr = learning_rate)
)
# Inicie o treinamento da rede neural
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = 0.5,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
model_nnet <- readRDS("path/to/model.rds")
load('rede_neural_10_04_2023.rda')
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
jogos <- select(jogos, ends_with("_diff"), ganhador)
jogos$ganhador <- as.factor(jogos$ganhador)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
data_split <- initial_split(jogos, prop = 0.7, strata = 'ganhador')
training_data <- training(data_split)
test_data <- testing(data_split)
# Carregando os dados --------------------------------------------------------------------------------------
jogos <- read.csv2('csv/partidas_teste_10_04_2023.csv') %>% dplyr::select(-X)
jogos$ganhador <- as.factor(jogos$ganhador)
s <- 281768
set.seed(s-1) #10679
data_split <- initial_split(jogos, prop = 0.7, strata = 'ganhador')
training_data <- training(data_split)
test_data <- testing(data_split)
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
test_data$ganhador <- as.factor(test_data$ganhador)
training_data$ganhador <- as.factor(training_data$ganhador)
predictions <- predict(n, test_data)
mse <- mean((test_data$y - predictions)^2)
test_data$ganhador
mse <- mean((test_data$ganhador - predictions)^2)
# Crie uma matriz de design numérica a partir dos dados de teste
test_design <- model.matrix(~ ., data = test_data)
# Calcule as previsões usando a matriz de design numérica
predictions <- predict(model, newdata = test_design)
# Calcule as previsões usando a matriz de design numérica
predictions <- predict(n, newdata = test_design)
# Converta as respostas em uma forma numérica
response_numeric <- as.numeric(as.character(test_data$ganhador))
# Calcule o MSE usando as previsões e as respostas numéricas
mse <- mean((response_numeric - predictions)^2)
# Salve o modelo como um artefato no servidor MLflow
mlflow_log_param("hidden_n", n$size)
mlflow_log_param("weight_decay", n$decay)
mlflow_log_param("num_epochs", n$nIter)
mlflow_log_metric("mse", mse)
n$size
n$weights
# Salve o modelo como um artefato no servidor MLflow
mlflow_log_param("hidden_n", 15)
mlflow_set_tracking_uri('http://localhost:5000') # define a URI do servidor de rastreamento
mlflow_create_experiment('rede_neural') # define o nome do experimento
mlflow server
# Definindo diretório --------------------------------------------------------------------------------------
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
# Carregando pacotes ---------------------------------------------------------------------------------------
pacotes <- c("remotes", "caret", "dplyr", "tidyr", "rvest", "rsample", "readr", "quantmod",
"httr", "tibble", "stringr", "neuralnet", "nnet", "ggplot2", "ModelMetrics",
"beepr", "purrr", "plotly", "pROC", "ROCR", "kableExtra", "glmnet", "valorant", 'mlflow')
for (pacote in pacotes) {
if (!require(pacote, character.only = TRUE)) {
if (!requireNamespace("remotes", quietly = TRUE)) {
install.packages("remotes")
}
remotes::install_github('Juniorffonseca/r-pacote-valorant')
if (!require(pacote, character.only = TRUE)) {
stop(paste("Pacote", pacote, "não encontrado"))
}
}
}
# alterar caminho da variável de ambiente do python
Sys.setenv(MLFLOW_BIN="./venv/Scripts/mlflow")
# alterar caminho da variável de ambiente do python
Sys.setenv(MLFLOW_PYTHON_BIN="./venv/Scripts/python")
# Carregando os dados --------------------------------------------------------------------------------------
jogos <- read.csv2('csv/partidas_teste_10_04_2023.csv') %>% dplyr::select(-X)
jogos$ganhador <- as.factor(jogos$ganhador)
s <- 281768
set.seed(s-1) #10679
data_split <- initial_split(jogos, prop = 0.7, strata = 'ganhador')
training_data <- training(data_split)
test_data <- testing(data_split)
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
test_data$ganhador <- as.factor(test_data$ganhador)
training_data$ganhador <- as.factor(training_data$ganhador)
mlflow_set_tracking_uri('http://localhost:5000') # define a URI do servidor de rastreamento
mlflow_create_experiment('rede_neural') # define o nome do experimento
mlflow_set_tracking_uri('http://localhost:5000') # define a URI do servidor de rastreamento
mlflow_create_experiment('rede_neural') # define o nome do experimento
mlflow_ui()
load('rede_neural_10_04_2023.rda')
predictions <- predict(n, test_data)
# Crie uma matriz de design numérica a partir dos dados de teste
test_design <- model.matrix(~ ., data = test_data)
# Calcule as previsões usando a matriz de design numérica
predictions <- predict(n, newdata = test_design)
# Converta as respostas em uma forma numérica
response_numeric <- as.numeric(as.character(test_data$ganhador))
# Calcule o MSE usando as previsões e as respostas numéricas
mse <- mean((response_numeric - predictions)^2)
# Salve o modelo como um artefato no servidor MLflow
mlflow_log_param("hidden_n", 15)
mlflow_log_metric("mse", mse)
mlflow_log_artifact("rede_neural_10_04_2023.rda", artifact_path = "n.rda")
?mlflow_log_model
mlflow_log_model('rede_neural_10_04_2023.rda', artifact_path = "n.rda")
mlflow_log_model(n, artifact_path = "n.rda")
# Instalando (se necessário) e carregando pacotes ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-04-11'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/previsao_diaria/', format(datas, '%Y-%m-%d'), '_previsoes.csv')
previsoes_lista <- list()
for (arquivo in nomes_arquivos) {
previsoes_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
previsoes_lista <- lapply(previsoes_lista, function(df) {
df %>% mutate(X = as.character(X))
})
previsoes <- bind_rows(previsoes_lista)
previsoes$ganhador <- as.factor(previsoes$ganhador)
previsoes$prev <- as.factor(previsoes$prev)
View(previsoes)
# Definindo diretório --------------------------------------------------------------------------------------
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
# Carregando pacotes ---------------------------------------------------------------------------------------
pacotes <- c("remotes", "caret", "dplyr", "tidyr", "rvest", "rsample", "readr", "quantmod",
"httr", "tibble", "stringr", "neuralnet", "nnet", "ggplot2", "ModelMetrics",
"beepr", "purrr", "plotly", "pROC", "ROCR", "kableExtra", "glmnet", "valorant")
for (pacote in pacotes) {
if (!require(pacote, character.only = TRUE)) {
if (!requireNamespace("remotes", quietly = TRUE)) {
install.packages("remotes")
}
remotes::install_github('Juniorffonseca/r-pacote-valorant')
if (!require(pacote, character.only = TRUE)) {
stop(paste("Pacote", pacote, "não encontrado"))
}
}
}
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
jogos <- select(jogos, ends_with("_diff"), ganhador)
jogos$ganhador <- as.factor(jogos$ganhador)
View(jogos)
# Definindo diretório --------------------------------------------------------------------------------------
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
# Carregando pacotes ---------------------------------------------------------------------------------------
pacotes <- c("remotes", "caret", "dplyr", "tidyr", "rvest", "rsample", "readr", "quantmod",
"httr", "tibble", "stringr", "neuralnet", "nnet", "ggplot2", "ModelMetrics",
"beepr", "purrr", "plotly", "pROC", "ROCR", "kableExtra", "glmnet", "valorant")
for (pacote in pacotes) {
if (!require(pacote, character.only = TRUE)) {
if (!requireNamespace("remotes", quietly = TRUE)) {
install.packages("remotes")
}
remotes::install_github('Juniorffonseca/r-pacote-valorant')
if (!require(pacote, character.only = TRUE)) {
stop(paste("Pacote", pacote, "não encontrado"))
}
}
}
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
jogos <- select(jogos, ends_with("_diff"), ganhador)
jogos$ganhador <- as.factor(jogos$ganhador)
# Definindo diretório --------------------------------------------------------------------------------------
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
# Carregando pacotes ---------------------------------------------------------------------------------------
pacotes <- c("remotes", "caret", "dplyr", "tidyr", "rvest", "rsample", "readr", "quantmod",
"httr", "tibble", "stringr", "neuralnet", "nnet", "ggplot2", "ModelMetrics",
"beepr", "purrr", "plotly", "pROC", "ROCR", "kableExtra", "glmnet", "valorant")
for (pacote in pacotes) {
if (!require(pacote, character.only = TRUE)) {
if (!requireNamespace("remotes", quietly = TRUE)) {
install.packages("remotes")
}
remotes::install_github('Juniorffonseca/r-pacote-valorant')
if (!require(pacote, character.only = TRUE)) {
stop(paste("Pacote", pacote, "não encontrado"))
}
}
}
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
jogos <- select(jogos, ends_with("_diff"), ganhador)
jogos$ganhador <- as.factor(jogos$ganhador)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
data_split <- initial_split(jogos, prop = 0.7, strata = 'ganhador')
training_data <- training(data_split)
test_data <- testing(data_split)
hidden_n <- c(15)
formula <- 'ganhador == 1 ~ .'
# Normalizando os dados -----------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = 0.5,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
# Prediction ----------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed --------------------------------------------------------------------------------------
s <- 281768
w <- 0.1
while ( i < 0.78) {
achar_Seed(s, hidden_n, t = 0.5, mostrar_i = F)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(round(w, 2))
}
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
urls <- bind_rows(urls_lista) %>% select(-X)
View(urls_lista)
urls <- bind_rows(urls_lista, make.names(unique = T)) %>% select(-X)
urls <- bind_rows(urls_lista, make.names(urls_lista, unique = T)) %>% select(-X)
urls <- bind_rows(urls_lista %>% select(-X))
urls <- bind_rows(urls_lista) %>% select(-X)
urls_lista[1]
urls_lista[2]
urls_lista[2,]
urls_lista[[2,]]
urls_lista[[2]]
urls_lista[[2]]$x
urls <- bind_rows(urls_lista[[]]) %>% select(-X)
urls <- bind_rows(urls_lista) %>% select(-X)
rlang::last_error()
urls <- bind_rows(str(urls_lista)) %>% select(-X)
urls <- bind_rows(urls_lista) %>% select(-X)
df <- do.call(df, urls_lista)
as_tibble(urls_lista)
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo) %>% select(-X)
}
View(urls_lista)
urls <- bind_rows(urls_lista) %>% select(-X)
urls <- bind_rows(urls_lista)
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo) %>% select(-X)
}
View(urls_lista)
urls_lista
urls_lista[]
urls_lista[1]
urls_lista[1,]
urls_lista[]$`csv/catalogacao_diaria/2023-02-20_urls.csv`
# Combina as matrizes em um único data frame
df <- do.call(rbind, urls_lista)
# Exibir o data frame resultante
df
View(df)
df <- do.call(data.frame, urls_lista)
df <- do.call(rbind, urls_lista)
# Exibir o data frame resultante
df
urls <- do.call(rbind, urls_lista)
rm(df)
View(urls)
row.names(urls) <- NULL
View(urls)
urls <- do.call(rbind, urls_lista)
row.names(urls) <- NULL
url_teste <- urls[1]
url_teste <- urls[1,]
url_teste
x <- read_html(url_teste) %>% html_nodes('div.wf-card match-h2h')
x <- read_html(url_teste) %>% html_node('div.wf-card match-h2h')
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h')
View(x)
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text()
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', '') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', '') %>% str_replace_all('\t', ' ')
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('span.rf') %>% html_text()
z
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text()
x
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', '') %>% str_replace_all('\t', '')
x
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('span.rf') %>% html_text()
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss') %>%
html_text()
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\n', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
