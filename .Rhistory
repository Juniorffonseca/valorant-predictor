data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
#plot(n, rep = 1)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
detach("package:valorant", unload = TRUE)
#Instalando pacotes (se necessário) e carregando ----------------------------------------------------------
library(devtools)
install_github("Juniorffonseca/r-pacote-valorant")
library(dplyr)
library(tidyr)
library(rvest)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date("2023-02-19"), Sys.Date() - 1, by = "day")
nomes_arquivos <- paste0("csv/catalogacao_diaria/", format(datas, "%Y-%m-%d"), "_partidas.csv")
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- read.csv2(arquivo) %>% select(-X)
}
jogos <- bind_rows(jogos_lista)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
prob_a <- 0.6
prob_b <- 0.4
hidden_n <- c(30)
n2 <- T
formula <- ganhador ~ .
inp <- sample(2, nrow(jogos), replace = TRUE, prob = c(prob_a, prob_b))
training_data <- jogos[inp==1, ]
test_data <- jogos[inp==2, ]
# Normalizando os dados ------------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
training_data$ganhador <- as.factor(training_data$ganhador)
test_data$ganhador <- as.factor(test_data$ganhador)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(ganhador == 1 ~ .,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
#plot(n, rep = 1)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
install_github("Juniorffonseca/r-pacote-valorant")
detach("package:valorant", unload = TRUE)
install_github("Juniorffonseca/r-pacote-valorant")
library(valorant)
detach("package:valorant", unload = TRUE)
install_github("Juniorffonseca/r-pacote-valorant")
install_github("Juniorffonseca/r-pacote-valorant")
install_github("Juniorffonseca/r-pacote-valorant")
install_github("Juniorffonseca/r-pacote-valorant")
install_github("Juniorffonseca/r-pacote-valorant")
#Instalando pacotes (se necessário) e carregando ----------------------------------------------------------
library(devtools)
install_github("Juniorffonseca/r-pacote-valorant")
library(dplyr)
library(tidyr)
library(rvest)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date("2023-02-19"), Sys.Date() - 1, by = "day")
nomes_arquivos <- paste0("csv/catalogacao_diaria/", format(datas, "%Y-%m-%d"), "_partidas.csv")
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- read.csv2(arquivo) %>% select(-X)
}
jogos <- bind_rows(jogos_lista)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
prob_a <- 0.6
prob_b <- 0.4
hidden_n <- c(30)
n2 <- T
formula <- ganhador ~ .
inp <- sample(2, nrow(jogos), replace = TRUE, prob = c(prob_a, prob_b))
training_data <- jogos[inp==1, ]
test_data <- jogos[inp==2, ]
# Normalizando os dados ------------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
training_data$ganhador <- as.factor(training_data$ganhador)
test_data$ganhador <- as.factor(test_data$ganhador)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(ganhador == 1 ~ .,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
#plot(n, rep = 1)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
n2 <- F
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
n2 <- F
formula <- ifelse(n2 == T, ganhador ~ ., ganhador == 1 ~ .)
formula <- ifelse(n2 == T, 'ganhador ~ .', 'ganhador == 1 ~ .')
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
plot(n, rep = 1)
n2 <- T
formula <- ifelse(n2 == T, 'ganhador ~ .', 'ganhador == 1 ~ .')
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
plot(n, rep = 1)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
prob_a <- 0.7
prob_b <- 0.3
hidden_n <- c(30)
n2 <- T
formula <- ifelse(n2 == T, 'ganhador ~ .', 'ganhador == 1 ~ .')
inp <- sample(2, nrow(jogos), replace = TRUE, prob = c(prob_a, prob_b))
training_data <- jogos[inp==1, ]
test_data <- jogos[inp==2, ]
# Normalizando os dados ------------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
training_data$ganhador <- as.factor(training_data$ganhador)
test_data$ganhador <- as.factor(test_data$ganhador)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
plot(n, rep = 1)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
View(predictVstest)
hidden_n <- c(30, 30, 30)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
if(n2 == T){
nn2 <<- ifelse(Predict$net.result[,1]>Predict$net.result[,2],1,0)
}
else{
if(n2 == T){
nn2 <<- ifelse(Predict$net.result[,1]>Predict$net.result[,2],1,0)
}
{
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
}
if(n2 == T){
nn2 <<- ifelse(Predict$net.result[,1]>Predict$net.result[,2],1,0)
} else{
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
}
detach("package:valorant", unload = TRUE)
#Instalando pacotes (se necessário) e carregando ----------------------------------------------------------
library(devtools)
install_github("Juniorffonseca/r-pacote-valorant")
library(dplyr)
library(tidyr)
library(rvest)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date("2023-02-19"), Sys.Date() - 1, by = "day")
nomes_arquivos <- paste0("csv/catalogacao_diaria/", format(datas, "%Y-%m-%d"), "_partidas.csv")
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- read.csv2(arquivo) %>% select(-X)
}
jogos <- bind_rows(jogos_lista)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
prob_a <- 0.7
prob_b <- 0.3
hidden_n <- c(30, 30, 30)
formula <- 'ganhador == 1 ~ .'
inp <- sample(2, nrow(jogos), replace = TRUE, prob = c(prob_a, prob_b))
training_data <- jogos[inp==1, ]
test_data <- jogos[inp==2, ]
# Normalizando os dados ------------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
training_data$ganhador <- as.factor(training_data$ganhador)
test_data$ganhador <- as.factor(test_data$ganhador)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
#plot(n, rep = 1)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
plot(n, rep = 1)
hidden_n <- c(30)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
plot(n, rep = 1)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
#Instalando pacotes (se necessário) e carregando ----------------------------------------------------------
library(devtools)
install_github("Juniorffonseca/r-pacote-valorant")
library(dplyr)
library(tidyr)
library(rvest)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(valorant)
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date("2023-02-19"), Sys.Date() - 1, by = "day")
nomes_arquivos <- paste0("csv/catalogacao_diaria/", format(datas, "%Y-%m-%d"), "_partidas.csv")
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- read.csv2(arquivo) %>% select(-X)
}
jogos <- bind_rows(jogos_lista)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
prob_a <- 0.7
prob_b <- 0.3
hidden_n <- c(30)
formula <- 'ganhador == 1 ~ .'
inp <- sample(2, nrow(jogos), replace = TRUE, prob = c(prob_a, prob_b))
training_data <- jogos[inp==1, ]
test_data <- jogos[inp==2, ]
# Normalizando os dados ------------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
training_data$ganhador <- as.factor(training_data$ganhador)
test_data$ganhador <- as.factor(test_data$ganhador)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = "sse",
linear.output = F,
threshold = 1,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
plot(n, rep = 1)
# Prediction ---------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed -------------------------------------------------------------------------------------
s <- 1 # 6093 = 0.86
w <- 0.1
while ( i < 0.83) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
while ( i < 0.80) {
achar_Seed(s, prob_a, prob_b, hidden_n)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(w)
}
# Atualizando a seed para achar a melhor neuralnetwork ----------------------------------------------------
set.seed(s-1) #4 #59
inp <- sample(2, nrow(jogos), replace = TRUE, prob = c(prob_a, prob_b))
training_data <- jogos[inp==1, ]
test_data <- jogos[inp==2, ]
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
training_data$ganhador <- as.factor(training_data$ganhador)
test_data$ganhador <- as.factor(test_data$ganhador)
Predict = compute(n, test_data)
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
# Procurando uma rede neural com acuracia a cima de determinado percentual --------------------------------
z <- 0.1
while (i < 0.96) {
achar_Nn()
}
while (i < 0.875) {
achar_Nn()
}
beep(8)
nn2 <- ifelse(Predict$net.result[,1]>0.5, 1, 0)
nn2 <- as.factor(nn2)
x <- caret::confusionMatrix(nn2, test_data$ganhador)
x <- as.data.frame(x$table)
# Plot
ggplot(data = x, mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), colour = 'white') +
geom_text(aes(label = sprintf('%1.0f', Freq)), vjust = 1) +
scale_fill_gradient(low = 'white', high = 'green') +
theme_bw() + theme(legend.position = 'none')
#Log Loss
logLoss(actual = test_data$ganhador, predicted = Predict$net.result)
View(predictVstest)
