if (!require(pacote, character.only = TRUE)) {
if (!requireNamespace("remotes", quietly = TRUE)) {
install.packages("remotes")
}
remotes::install_github('Juniorffonseca/r-pacote-valorant')
if (!require(pacote, character.only = TRUE)) {
stop(paste("Pacote", pacote, "não encontrado"))
}
}
}
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
jogos_lista <- list()
for (arquivo in nomes_arquivos) {
jogos_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
jogos <- bind_rows(jogos_lista) %>% select(-X)
vars <- c('RND', 'R', 'ACS', 'KAST', 'KD', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'K', 'D', 'A', 'FK', 'FD')
for (i in vars) {
new_var <- paste0(i, "_diff")
jogos[[new_var]] <- jogos[[paste0("time1", i)]] - jogos[[paste0("time2", i)]]
}
jogos <- select(jogos, ends_with("_diff"), ganhador)
jogos$ganhador <- as.factor(jogos$ganhador)
# Criando dataframes de teste e validação -----------------------------------------------------------------
set.seed(1)
data_split <- initial_split(jogos, prop = 0.7, strata = 'ganhador')
training_data <- training(data_split)
test_data <- testing(data_split)
hidden_n <- c(15)
formula <- 'ganhador == 1 ~ .'
# Normalizando os dados -----------------------------------------------------------------------------------
normalizando_test <- dplyr::select(test_data, -ganhador)
normalizando_test <- as.data.frame(scale(normalizando_test))
test_data <- dplyr::select(test_data, ganhador)
test_data <- cbind(normalizando_test, test_data)
normalizando_training <- dplyr::select(training_data, -ganhador)
normalizando_training <- as.data.frame(scale(normalizando_training))
training_data <- dplyr::select(training_data, ganhador)
training_data <- cbind(normalizando_training, training_data)
# Modelando a rede neural ---------------------------------------------------------------------------------
n <- neuralnet(formula,
data = training_data,
hidden = hidden_n,
err.fct = 'sse',
linear.output = F,
threshold = 0.5,
lifesign = 'minimal',
rep = 1,
algorithm = 'rprop-',
stepmax = 10000)
# Prediction ----------------------------------------------------------------------------------------------
Predict = compute(n, test_data)
nn2 <<- ifelse(Predict$net.result[,1]>0.5,1,0)
predictVstest <- cbind(test_data, Predict$net.result)
i <<- sum(predictVstest$ganhador == nn2)/ nrow(test_data)
# Achar uma boa seed --------------------------------------------------------------------------------------
s <- 281768
w <- 0.1
while ( i < 0.78) {
achar_Seed(s, hidden_n, t = 0.5, mostrar_i = F)
s <- s + 1
w <<- ifelse(i>w, w <<- i, w <<- w)
print(round(w, 2))
}
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_partidas.csv')
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-02-19'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/catalogacao_diaria/', format(datas, '%Y-%m-%d'), '_urls.csv')
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
urls <- bind_rows(urls_lista) %>% select(-X)
View(urls_lista)
urls <- bind_rows(urls_lista, make.names(unique = T)) %>% select(-X)
urls <- bind_rows(urls_lista, make.names(urls_lista, unique = T)) %>% select(-X)
urls <- bind_rows(urls_lista %>% select(-X))
urls <- bind_rows(urls_lista) %>% select(-X)
urls_lista[1]
urls_lista[2]
urls_lista[2,]
urls_lista[[2,]]
urls_lista[[2]]
urls_lista[[2]]$x
urls <- bind_rows(urls_lista[[]]) %>% select(-X)
urls <- bind_rows(urls_lista) %>% select(-X)
rlang::last_error()
urls <- bind_rows(str(urls_lista)) %>% select(-X)
urls <- bind_rows(urls_lista) %>% select(-X)
df <- do.call(df, urls_lista)
as_tibble(urls_lista)
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo) %>% select(-X)
}
View(urls_lista)
urls <- bind_rows(urls_lista) %>% select(-X)
urls <- bind_rows(urls_lista)
urls_lista <- list()
for (arquivo in nomes_arquivos) {
urls_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo) %>% select(-X)
}
View(urls_lista)
urls_lista
urls_lista[]
urls_lista[1]
urls_lista[1,]
urls_lista[]$`csv/catalogacao_diaria/2023-02-20_urls.csv`
# Combina as matrizes em um único data frame
df <- do.call(rbind, urls_lista)
# Exibir o data frame resultante
df
View(df)
df <- do.call(data.frame, urls_lista)
df <- do.call(rbind, urls_lista)
# Exibir o data frame resultante
df
urls <- do.call(rbind, urls_lista)
rm(df)
View(urls)
row.names(urls) <- NULL
View(urls)
urls <- do.call(rbind, urls_lista)
row.names(urls) <- NULL
url_teste <- urls[1]
url_teste <- urls[1,]
url_teste
x <- read_html(url_teste) %>% html_nodes('div.wf-card match-h2h')
x <- read_html(url_teste) %>% html_node('div.wf-card match-h2h')
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h')
View(x)
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text()
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', '') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', '') %>% str_replace_all('\t', ' ')
x
x <- read_html(url_teste) %>% html_nodes('div.wf-card.match-h2h') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('span.rf') %>% html_text()
z
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text()
x
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', '') %>% str_replace_all('\t', '')
x
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('span.rf') %>% html_text()
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss') %>%
html_text()
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\n', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
# Definindo diretório --------------------------------------------------------------------------------------
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
# Carregando pacotes ---------------------------------------------------------------------------------------
pacotes <- c("remotes", "caret", "dplyr", "tidyr", "rvest", "rsample", "readr", "quantmod",
"httr", "tibble", "stringr", "neuralnet", "nnet", "ggplot2", "ModelMetrics",
"beepr", "purrr", "plotly", "pROC", "ROCR", "kableExtra", "glmnet", "valorant")
for (pacote in pacotes) {
if (!require(pacote, character.only = TRUE)) {
if (!requireNamespace("remotes", quietly = TRUE)) {
install.packages("remotes")
}
remotes::install_github('Juniorffonseca/r-pacote-valorant')
if (!require(pacote, character.only = TRUE)) {
stop(paste("Pacote", pacote, "não encontrado"))
}
}
}
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
x
url_teste
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('span.rf', 'span.ra') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('span.rf.ra') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('span.rf' | 'span.ra') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
placares <- as.integer(z[seq_along(z) %% 2 == 1])
placares
placares <- z[seq_along(z) %% 2 == 1] # selecionar apenas os placares
placares <- gsub("[^0-9]+", "", placares) # remover caracteres não numéricos
placares <- as.integer(placares) # converter para números inteiros
placares
placares <- as.integer(z[seq_along(z) %% 2 == 2])
placares <- as.integer(c(z[seq(from = 1, to = length(z), by = 4)],
z[seq(from = 2, to = length(z), by = 4)]))
placares
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
str_match(x, "^\\s*(\\d+)\\s*(\\d+)\\s*$")
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match(placares, "^\\s*(\\d+)\\s*(\\d+)\\s*$")
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match(placares, "^\\s*(\\d+)\\s*(\\d+)\\s*$")
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match(x, "^\\s*(\\d+)\\s*(\\d+)\\s*$")
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match("^\\s*(\\d+)\\s*(\\d+)\\s*$")
x
t1 <- as.integer(matches[, 2])
t2 <- as.integer(matches[, 3])
t1 <- as.integer(x[, 2])
t2 <- as.integer(x[, 3])
x
t[,1] <- as.integer(x[, 2])
t[,2] <- as.integer(x[, 3])
x[,1] <- as.integer(x[, 2])
x[,2] <- as.integer(x[, 3])
x
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match("^\\s*(\\d+)\\s*(\\d+)\\s*$")
x
x <- x[,-1]
x
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match("^\\s*(\\d+)\\s*(\\d+)\\s*$")
x <- x[,-1]
ul_teste <- 'https://www.vlr.gg/170958/crazy-raccoon-vs-scarz-challengers-league-japan-split-1-uf'
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match("^\\s*(\\d+)\\s*(\\d+)\\s*$")
x <- x[,-1]
x
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match("^\\s*(\\d+)\\s*(\\d+)\\s*$")
x
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
x
url_teste <- 'https://www.vlr.gg/170958/crazy-raccoon-vs-scarz-challengers-league-japan-split-1-uf'
rm(ul_teste)
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match("^\\s*(\\d+)\\s*(\\d+)\\s*$")
x <- x[,-1]
x
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.wf-card.mod-dark.match-histories.mod-first.mod-loss span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result.mod-') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result.mod- span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
z
matches <- str_match(z, "^\\s*(\\d+)\\s*(\\d+)\\s*$")
z
z <- str_match(z, "^\\s*(\\d+)\\s*(\\d+)\\s*$")
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
# Converter os resultados das partidas para números inteiros
resultados <- as.integer(z)
# Calcular o número de linhas e colunas necessárias para a matriz
n_partidas <- length(resultados)
n_colunas <- 2
n_linhas <- ceiling(n_partidas / n_colunas)
# Criar uma matriz para armazenar os resultados das partidas
matriz_resultados <- matrix(NA, nrow = n_linhas, ncol = n_colunas)
# Preencher a matriz com os resultados das partidas
for (i in 1:n_partidas) {
linha <- ceiling(i / n_colunas)
coluna <- i - (linha - 1) * n_colunas
matriz_resultados[linha, coluna] <- resultados[i]
}
# Imprimir a matriz de resultados
matriz_resultados
# Calcular o número de linhas e colunas necessárias para a matriz
n_partidas <- length(z)
n_colunas <- 2
n_linhas <- ceiling(n_partidas / n_colunas)
# Criar uma matriz para armazenar os resultados das partidas
matriz_resultados <- matrix(NA, nrow = n_linhas, ncol = n_colunas)
# Preencher a matriz com os resultados das partidas
for (i in 1:n_partidas) {
linha <- ceiling(i / n_colunas)
coluna <- i - (linha - 1) * n_colunas
matriz_resultados[linha, coluna] <- resultados[i]
}
# Imprimir a matriz de resultados
matriz_resultados
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
n_partidas <- length(z)
n_linhas <- ceiling(length(z) / 2)
# Criar uma matriz para armazenar os resultados das partidas
matriz_resultados <- matrix(NA, nrow = n_linhas, ncol = 2)
# Preencher a matriz com os resultados das partidas
for (i in 1:n_partidas) {
linha <- ceiling(i / 2)
coluna <- i - (linha - 1) * 2
matriz_resultados[linha, coluna] <- resultados[i]
}
# Imprimir a matriz de resultados
matriz_resultados
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
n_linhas <- ceiling(length(z) / 2)
# Criar uma matriz para armazenar os resultados das partidas
y <- matrix(NA, nrow = n_linhas, ncol = 2)
for (i in 1:n_partidas) {
linha <- ceiling(i / 2)
coluna <- i - (linha - 1) * 2
y[linha, coluna] <- resultados[i]
}
y
# H2H
x <- read_html(url_teste) %>% html_nodes('div.match-h2h-matches-score') %>% html_text() %>%
str_replace_all('\n', ' ') %>% str_replace_all('\t', '') %>%
str_match("^\\s*(\\d+)\\s*(\\d+)\\s*$")
x <- x[,-1] ## Finalizado praticamente, agr só preciso colocar para iterar em todos os links
x
t1 <- sum(x[,1])
t1 <- sum(as.numeric(x[,1]))
t2 <- sum(as.numeric(x[,2]))
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
n_linhas <- ceiling(length(z) / 2)
# Criar uma matriz para armazenar os resultados das partidas
y <- matrix(NA, nrow = n_linhas, ncol = 2)
for (i in 1:n_partidas) {
linha <- ceiling(i / 2)
coluna <- i - (linha - 1) * 2
y[linha, coluna] <- resultados[i]
}
# Past Matchs
z <- read_html(url_teste) %>% html_nodes('div.match-histories-item-result span') %>%
html_text() %>% str_replace_all('\n', ' ') %>% str_replace_all('\t', '')
z
wins <- sum(z[1], z[3], z[5], z[7], z[9])
z <- as.numeric(z)
wins <- sum(z[1], z[3], z[5], z[7], z[9])
rm(win)
rm(wins)
loses_t1 <- sum(z[2], z[4], z[6], z[8], z[10])
less()
profit_t1 <- (wins_t1 - loses_t1)
wins_t1 <- sum(z[1], z[3], z[5], z[7], z[9])
loses_t1 <- sum(z[2], z[4], z[6], z[8], z[10])
profit_t1 <- (wins_t1 - loses_t1)
z
wins_t2 <- sum(z[11], z[13], z[15], z[17], z[19])
loses_t2 <- sum(z[12], z[14], z[16], z[18], z[20])
profit_t2 <- (wins_t2 - loses_t2)
past_matches <- c(profit_t1, profit_t2)
past_matches
h2h <- c(t1, t2)
h2h
h2h <- cbind(t1, t2)
h2h
past_matches <- cbind(profit_t1, profit_t2)
past_matches
# Instalando (se necessário) e carregando pacotes ----------------------------------------------------------
remotes::install_github('Juniorffonseca/r-pacote-valorant')
library(caret)
library(dplyr)
library(tidyr)
library(rvest)
library(rsample)
library(readr)
library(quantmod)
library(httr)
library(tibble)
library(stringr)
library(neuralnet)
library(nnet)
library(caret)
library(ggplot2)
library(ModelMetrics)
library(beepr)
library(purrr)
library(plotly)
library(pROC)
library(ROCR)
library(kableExtra)
library(glmnet)
library(valorant)
setwd('C:/Users/anonb/Documents/TCC_Pós/Scripts')
# Carregando partidas diarias e unindo em um df ------------------------------------------------------------
datas <- seq(as.Date('2023-04-11'), Sys.Date() - 1, by = 'day')
nomes_arquivos <- paste0('csv/previsao_diaria/', format(datas, '%Y-%m-%d'), '_previsoes.csv')
previsoes_lista <- list()
for (arquivo in nomes_arquivos) {
previsoes_lista[[arquivo]] <- possibly(read.csv2, otherwise = NULL)(arquivo)
}
previsoes_lista <- lapply(previsoes_lista, function(df) {
df %>% mutate(X = as.character(X))
})
previsoes <- bind_rows(previsoes_lista)
previsoes$ganhador <- as.factor(previsoes$ganhador)
previsoes$prev <- as.factor(previsoes$prev)
#Plot distribuição
plot_ly(data = previsoes, x = ~V1_n, y = ~ganhador,
color = ~factor(ganhador), colors = c('red', 'green'), type = 'scatter',
mode = 'markers', marker = list(size = 3)) %>%
layout(xaxis = list(title = 'Porcentagem'), yaxis = list(title = 'Ganhador'),
legend = list(title = 'Ganhador', font = list(size = 16)),
margin = list(l = 50, r = 50, t = 50, b = 50),
shapes = list(list(type = 'line', x0 = 50, x1 = 50, y0 = 0, y1 = 1,
line = list(color = 'gray', width = 2))))
# Plot distribuição das probabilidades por densidade
ggplot(data = previsoes, aes(x = V1_n, fill = ganhador)) +
geom_density(alpha = 0.5) +
scale_fill_manual(values = c('red', 'green')) +
labs(x = 'Porcentagem', y = 'Densidade', fill = 'Ganhador') +
theme_bw()
# Loop através das URLs em previsoes$b e extrai as odds
for (i in 1:nrow(previsoes)) {
url <- previsoes$b[i]
odds <- read_html(url) %>%
html_nodes('div.match-bet-item-half') %>%
html_text() %>%
str_replace_all('\t', '') %>%
str_replace_all('\n', '') %>%
.[1] %>%
gsub(".*?(\\d+\\.\\d+).*", "\\1", .)
previsoes$odds[i] <- odds
}
previsoes$odds <- as.numeric(previsoes$odds)
acertos <- previsoes %>% filter(ganhador == prev)
erros <- previsoes %>% filter(ganhador != prev)
